{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.filters import roberts\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import clear_border\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "annotations = pd.read_csv(\"annotations.csv\")\n",
    "\n",
    "##################################################################################################################################\n",
    "###### function given by Luna16 challenge administrators to assist in converting coordinates from the  candidates data set #######\n",
    "##################################################################################################################################\n",
    "\n",
    "\n",
    "def worldToVoxelCoord(worldCoord, origin, spacing):\n",
    "    stretchedVoxelCoord = np.absolute(worldCoord - origin)\n",
    "    voxelCoord = stretchedVoxelCoord / spacing\n",
    "    return voxelCoord\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "######                                       end code from Luna16                                                     #######\n",
    "############################################################################################################################\n",
    "\n",
    "\n",
    "def pixel_diameter(spacing, diameter):\n",
    "    px_diam = np.absolute(diameter) / spacing\n",
    "    px_diam = [int(np.floor(i)) for i in px_diam]\n",
    "    return px_diam\n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    # get image and pull origin and spacing for translating nodule coordinates from file\n",
    "    ct_scan = sitk.ReadImage(image, sitk.sitkFloat32)\n",
    "    numpyOrigin = np.array(list(reversed(ct_scan.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(ct_scan.GetSpacing())))\n",
    "    ct_scan = sitk.GetArrayFromImage(ct_scan)\n",
    "\n",
    "    # blur image\n",
    "    ct_scan_thresh_mask = gaussian_filter(ct_scan, sigma=(5, 5, 0))\n",
    "\n",
    "    # already in hounsfield units\n",
    "    # range of tissue and bronchioles to keep: study doesn't give exact number (close to -1000 or above -320 masked)\n",
    "    min_hu = -900\n",
    "    max_hu = -320\n",
    "    ct_scan_thresh_mask = np.clip(ct_scan_thresh_mask, min_hu, max_hu)\n",
    "    ct_scan_thresh_mask = ct_scan_thresh_mask < -400\n",
    "    \n",
    "    #######################################################################################################\n",
    "    ##https://www.kaggle.com/code/arnavkj95/candidate-generation-and-luna16-preprocessing/notebook########\n",
    "    ##### preprocessing ideas taken from the above website ###############################################\n",
    "    #######################################################################################################\n",
    "\n",
    "    # remove peices of scan that aren't part of lung tissues\n",
    "    for i in range(ct_scan_thresh_mask.shape[0]):\n",
    "        ct_scan_thresh_mask[i] = clear_border(ct_scan_thresh_mask[i])\n",
    "        edges = roberts(ct_scan_thresh_mask[i])\n",
    "        ct_scan_thresh_mask[i] = ndi.binary_fill_holes(edges)\n",
    "\n",
    "    # assign masked regions to original ct\n",
    "    ct_scan[ct_scan_thresh_mask == False] = -3024\n",
    "    ct_scan[ct_scan < -400] = -3024\n",
    "    \n",
    "    #######################################################################################################\n",
    "    ##### End preprocesing ideas########################### ###############################################\n",
    "    #######################################################################################################\n",
    "\n",
    "    # set to between 0 and 1 for model\n",
    "    for i in range(ct_scan.shape[0]):\n",
    "        # Need to normal 0-1 and zero_center\n",
    "        ct_scan[i] = minmax_scale(ct_scan[i], feature_range=(0, 1))\n",
    "\n",
    "    # 3d spline interpolation to 0.5 in xyz directions\n",
    "    ct_scan = resize(ct_scan, (int(ct_scan.shape[0] / 2), 256, 256), mode=\"reflect\")\n",
    "\n",
    "    # zero mean to make data symmetric\n",
    "    meanCenter = lambda x: x - x.mean()\n",
    "    ct_scan = meanCenter(ct_scan)\n",
    "\n",
    "    return ct_scan, numpyOrigin, numpySpacing\n",
    "\n",
    "\n",
    "def output_data(ct_scan, numpyOrigin, numpySpacing, file, annotations):\n",
    "    zeros = np.zeros(ct_scan.shape)\n",
    "    nodules = annotations[annotations[\"seriesuid\"] == file]\n",
    "    nodules.reset_index(drop=True, inplace=True)\n",
    "    for i in range(len(nodules)):\n",
    "        print(\"has nodule\")\n",
    "        coordinates = (nodules[\"coordZ\"][i], nodules[\"coordY\"][i], nodules[\"coordX\"][i])\n",
    "        nodule_loc = worldToVoxelCoord(coordinates, numpyOrigin, numpySpacing)\n",
    "        nodule_loc = [int(np.floor(j)) for j in nodule_loc]\n",
    "        px_diam = pixel_diameter(numpySpacing, nodules[\"diameter_mm\"][i])\n",
    "\n",
    "        # use a box instead of circle as a circle would be slower\n",
    "        zeros[\n",
    "            int(int(nodule_loc[0] / 2) - max(round(px_diam[0] / 4, 0), 1)) : int(\n",
    "                int(nodule_loc[0] / 2) + max(round(px_diam[0] / 4, 0), 1) + 1\n",
    "            ),\n",
    "            int(nodule_loc[1] / 2 - max(round(px_diam[1] / 4, 0), 1)) : int(\n",
    "                nodule_loc[1] / 2 + max(round(px_diam[1] / 4, 0), 1) + 1\n",
    "            ),\n",
    "            int(nodule_loc[2] / 2 - max(round(px_diam[2] / 4, 0), 1)) : int(\n",
    "                nodule_loc[2] / 2 + max(round(px_diam[2] / 4, 0), 1) + 1\n",
    "            ),\n",
    "        ] = 1\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def get_unet_input():\n",
    "    folders = [\n",
    "        \"subset0/subset0/\",\n",
    "        \"subset1/subset1/\",\n",
    "        \"subset2/subset2/\",\n",
    "        \"subset3/subset3/\",\n",
    "        \"subset4/subset4/\",\n",
    "        \"subset5/subset5/\",\n",
    "        \"subset6/subset6/\",\n",
    "        \"subset7/subset7/\",\n",
    "        \"subset8/subset8/\",\n",
    "        \"subset9/subset9/\",\n",
    "    ]\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    files = os.listdir(folder)\n",
    "    files = [i[:-4] for i in files if i[-4:] == \".mhd\"]\n",
    "    print(\"files: \", len(files))\n",
    "    for file in files:\n",
    "        image = str(folder) + str(file) + \".mhd\"\n",
    "        ct_scan, numpyOrigin, numpySpacing = preprocess(image)\n",
    "        zeros = output_data(ct_scan, numpyOrigin, numpySpacing, file, annotations)\n",
    "        inputs.extend(ct_scan)\n",
    "        outputs.extend(zeros)\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "def train_unet(X_train, y_train):\n",
    "    #############################################################################################################################################################\n",
    "    ############### Code mostly taken from DigitalSreeni at https://www.youtube.com/watch?v=GAYJ81M58y8 ################################################################\n",
    "    ############### Using this code as it matches the U-Net model needed, with updates to parameters and the addition of dropout layers #################\n",
    "    ##############################################################################################################################################################\n",
    "    from keras.utils import normalize\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.layers import (\n",
    "        Conv2D,\n",
    "        MaxPooling2D,\n",
    "        Input,\n",
    "        UpSampling2D,\n",
    "        Dropout,\n",
    "        concatenate,\n",
    "    )\n",
    "    from tensorflow.keras.models import Model\n",
    "\n",
    "    # convolutions\n",
    "    inputs = Input((256, 256, 1))\n",
    "    s1 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    s1 = Dropout(0.2)(s1)\n",
    "    s1 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(s1)\n",
    "    p1 = MaxPooling2D(pool_size=(2, 2))(s1)\n",
    "\n",
    "    s2 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(p1)\n",
    "    s2 = Dropout(0.2)(s2)\n",
    "    s2 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(s2)\n",
    "    p2 = MaxPooling2D(pool_size=(2, 2))(s2)\n",
    "\n",
    "    s3 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(p2)\n",
    "    s3 = Dropout(0.2)(s3)\n",
    "    s3 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(s3)\n",
    "    p3 = MaxPooling2D(pool_size=(2, 2))(s3)\n",
    "\n",
    "    s4 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(p3)\n",
    "    s4 = Dropout(0.2)(s4)\n",
    "    s4 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(s4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(s4)\n",
    "\n",
    "    # bridge across U\n",
    "    b1 = Conv2D(1024, 3, activation=\"relu\", padding=\"same\")(p4)\n",
    "    b1 = Dropout(0.2)(b1)\n",
    "    b1 = Conv2D(1024, 3, activation=\"relu\", padding=\"same\")(b1)\n",
    "\n",
    "    d1 = Conv2D(512, 2, activation=\"relu\", padding=\"same\")(\n",
    "        UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(b1)\n",
    "    )\n",
    "    d1 = concatenate([s4, d1], axis=3)\n",
    "    d1 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(d1)\n",
    "    d1 = Dropout(0.2)(d1)\n",
    "    d1 = Conv2D(512, 3, activation=\"relu\", padding=\"same\")(d1)\n",
    "\n",
    "    d2 = Conv2D(256, 2, activation=\"relu\", padding=\"same\")(\n",
    "        UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d1)\n",
    "    )\n",
    "    d2 = concatenate([s3, d2], axis=3)\n",
    "    d2 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(d2)\n",
    "    d2 = Dropout(0.2)(d2)\n",
    "    d2 = Conv2D(256, 3, activation=\"relu\", padding=\"same\")(d2)\n",
    "\n",
    "    d3 = Conv2D(128, 2, activation=\"relu\", padding=\"same\")(\n",
    "        UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d2)\n",
    "    )\n",
    "    d3 = concatenate([s2, d3], axis=3)\n",
    "    d3 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(d3)\n",
    "    d3 = Dropout(0.2)(d3)\n",
    "    d3 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(d3)\n",
    "\n",
    "    d4 = Conv2D(64, 2, activation=\"relu\", padding=\"same\")(\n",
    "        UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(d3)\n",
    "    )\n",
    "    d4 = concatenate([s1, d4], axis=3)\n",
    "    d4 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(d4)\n",
    "    d4 = Dropout(0.2)(d4)\n",
    "    d4 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(d4)\n",
    "    d4 = Conv2D(2, 3, activation=\"relu\", padding=\"same\")(d4)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"unet\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    ############################################################################################\n",
    "    ########## end code taken from DigitalSreeni ###############################################\n",
    "    ###################### at https://www.youtube.com/watch?v=GAYJ81M58y8#######################\n",
    "    ############################################################################################\n",
    "\n",
    "    # get top 8 suspicious non-overlapping regions for cancer/non-cancer\n",
    "\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "    # fit model and show results of each epoch\n",
    "    checkpoint_name = \"Weights-{epoch:03d}--{val_loss:.5f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        checkpoint_name, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"auto\"\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    #train model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=10, callbacks=callbacks_list)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training data\n",
    "inputs, outputs = get_unet_input()\n",
    "np_input = np.array(inputs)\n",
    "np_input = np_input.reshape(len(np_input), 256, 256, 1)\n",
    "np_output = np.array(outputs)\n",
    "np_output = np_output.reshape(len(np_output), 256, 256, 1)\n",
    "\n",
    "#save training data\n",
    "import pickle\n",
    "filename = \"inputs_0502\".sav\"\n",
    "pickle.dump(np_input, open(filename, 'wb'))\n",
    "filename = \"outputs_0502\".sav\"\n",
    "pickle.dump(np_output, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train unet\n",
    "train_unet(np_input, np_output)\n",
    "filename = \"model_0502TF_2\".sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
